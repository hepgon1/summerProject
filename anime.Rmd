---
title: "anime"
author: "Garcia.Heather"
date: "July 8, 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sqldf)
```

Main is on the bottom of this file. 

64M records in the file.
83K for one anime show (21)

## Process the user to anime file. 
There are 64Mil rows in the file.  We cannot read it into memory in it's entirity.  
We plan to run this with a few randomly sampled anime ids so that we can create a sample of the data. 
```{r}
prc.usr.anime.file = function(rc, wd){
  # how many rows to count and the skip for the for loop.
  rowcnt= rc
  skp = 0
  
  #How many times to run the loop based upon the size of the file
  loop.number = ceiling(64000000/rowcnt)
  
  #The files that we are going to read and write, Shortens the code below.
  usr.anime.file = paste0(wd, "/myAnimeList Dataset/extracted data/UserAnimeList.csv")
  wrt.usr.anime.file = paste0(wd,"/code/output/MycleanUserAnimeList.csv")
  
  #Read the file and process rowcnt number of rows to pull an anime from the list of users. 
  for (i in 1:5){
    if(i==1){
      pr = read.csv(usr.anime.file, nrows = rowcnt, skip = skp, header = T)
      write.table(pr[which(pr[,2] == 21),], wrt.usr.anime.file, append = T, sep = ",", col.names = T, row.names = F)
    }else{
      pr = read.csv(usr.anime.file, nrows = rowcnt, skip = skp, header = F)
      write.table(pr[which(pr[,2] == 21),], wrt.usr.anime.file, append = T, sep = ",", col.names = F, row.names = F)
    }
    
    skp = skp + rowcnt
    
    #print(skp) 
    #print(head(pr))
    print(nrow(pr))
  }
}

```

#Read in the file
```{r}
read.file = function (dir, f){
  file = paste0(wd, "/", dir, "/", f)
  ds = read.csv(file, sep = ",", header = T)
  return (ds)
}

```

#Join the datasets
```{r}
join = function(){
  joined.ds = sqldf("select a.title, a.type, a.source, a.episodes, a.status, a.airing, a.aired_string, a.duration, a.rating, a.score, a.scored_by, a.rank, a.popularity, a.members, a.favorites, a.background, a.premiered, a.broadcast, a.related, a.producer, a.licensor, a.studio, a.genre, a.opening_theme, a.ending_theme, m.username, m.my_watched_episodes, m.my_start_date, m.my_finish_date, m.my_score, m.my_status,  m.my_rewatching, m.my_rewatching_ep, u.user_watching, u.user_completed,  u.user_onhold, u.user_dropped, u.user_plantowatch, u.user_days_spent_watching, u.gender, u.location, u.birth_date, u.access_rank, u.join_date, u.last_online
      from ani as a 
      join myusrAni as m
        on a.anime_id = m.anime_id
      join usr as u
        on u.username = m.username")
   wrt.usr.anime.file = paste0(wd,"/code/output/joinedDS.csv")
  write.table(joined.ds, wrt.usr.anime.file, append = F, sep = ",", col.names = T, row.names = F)
  return(joined.ds)
}
```


#Main
```{r}
setwd("D:/Data Analytic Applications/anime")
wd = getwd()

prc.usr.anime.file(2000, wd)

myusrAni = read.file("/code/output/", "MycleanUserAnimeList.csv")
myusrAni

ani = read.file("/myAnimeList Dataset/extracted data/", "AnimeList.csv")
head(ani)

usr = read.file("/myAnimeList Dataset/extracted data/", "UserList.csv")
head(usr)

all.ds = join()
```




