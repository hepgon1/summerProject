---
title: "anime"
author: "Garcia.Heather"
date: "July 8, 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sqldf)
library(caret)
library(timeDate)
library(dplyr)
```

Main is on the bottom of this file. 

64M records in the file.
83K for one anime show (21)

## Process the user to anime file. 
There are 64Mil rows in the file.  We cannot read it into memory in it's entirity.  
We plan to run this with a few randomly sampled anime ids so that we can create a sample of the data. 
```{r}
prc.usr.anime.file = function(rc, wd){
  # how many rows to count and the skip for the for loop.
  rowcnt= rc
  skp = 0
  
  #How many times to run the loop based upon the size of the file
  loop.number = ceiling(64000000/rowcnt)
  
  #The files that we are going to read and write, Shortens the code below.
  usr.anime.file = paste0(wd, "/myAnimeList Dataset/extracted data/UserAnimeList.csv")
  wrt.usr.anime.file = paste0(wd,"/code/output/MycleanUserAnimeList.csv")
  
  #Read the file and process rowcnt number of rows to pull an anime from the list of users. 
  #pr[which(pr[,2] == 21),]
  
  set.seed(123)
  for (i in 1:300){
    if(i==1){
      pr = read.csv(usr.anime.file, nrows = rowcnt, skip = skp, header = T)
      write.table(pr[sample(nrow(pr), 20),], wrt.usr.anime.file, append = T, sep = ",", col.names = T, row.names = F)
    }else{
      pr = read.csv(usr.anime.file, nrows = rowcnt, skip = skp, header = F)
      write.table(pr[sample(nrow(pr), 20),], wrt.usr.anime.file, append = T, sep = ",", col.names = F, row.names = F)
    }
    
    skp = skp + rowcnt
    
    #print(skp) 
    #print(head(pr))
    #print(nrow(pr))
  }
}

```

#Read in the file
```{r}
read.file = function (dir, f){
  file = paste0(wd, "/", dir, "/", f)
  ds = read.csv(file, sep = ",", header = T)
  return (ds)
}

```

#Join the datasets

a.title, a.type, a.source, a.episodes, a.aired_string, a.duration, a.rating, a.score, a.scored_by, a.rank, a.popularity, a.members, a.favorites, a.premiered, a.broadcast, a.related, a.producer, a.licensor, a.studio, a.genre, a.opening_theme, a.ending_theme, 
```{r}
join = function(){
  joined.ds = sqldf("select a.title, a.type, a.source, a.episodes, a.aired_string, a.duration, a.rating, a.score, a.scored_by, a.rank, a.popularity, a.members, a.favorites, a.premiered, a.broadcast, a.producer, a.licensor, a.studio, a.genre,  m.username, m.my_watched_episodes, m.my_start_date, m.my_finish_date, m.my_score, m.my_status,  m.my_rewatching, m.my_rewatching_ep, u.user_watching, u.user_completed,  u.user_onhold, u.user_dropped, u.user_plantowatch, u.gender, u.location, u.join_date, u.last_online
      from ani as a 
      join myusrAni as m
        on a.anime_id = m.anime_id
      join usr as u
        on u.username = m.username")
  #wrt.usr.anime.file = paste0(wd,"/code/output/joinedDS.csv")
  #write.table(joined.ds, wrt.usr.anime.file, append = F, sep = ",", col.names = T, row.names = F)
  return(joined.ds)
}
```

#Main
```{r}
setwd("D:/Data Analytic Applications/anime")
wd = getwd()

prc.usr.anime.file(2000, wd)
```
```{r}
myusrAni = read.file("/code/output/", "MycleanUserAnimeList.csv")
nrow(myusrAni)

ani = read.file("/myAnimeList Dataset/extracted data/", "AnimeList.csv")
head(ani)

usr = read.file("/myAnimeList Dataset/extracted data/", "UserList.csv")
head(usr)

```
```{r}
all_ds = join()
summary(all.ds)
```

#Evaluation of the sample dataset
If we get a random sample from the User to Anime list then we see a pretty nice sample of number of times a users did a score, the number of times the anime show occurs in the list and the distribution of the scores are reasonable. (More high than low, greater counts in the high range. 
```{r}


sqldf("select title, count(title) as cnt
      from all_ds
      group by title
      order by cnt desc ")
sqldf("select username, count(username) as cnt
      from all_ds
      group by username
      order by cnt desc ")
sqldf("select my_score, count(my_score) as cnt
      from all_ds
      group by my_score
      order by cnt desc ")
```

#Exploration
```{r}
str(ani)
summary(ani[,-c(2, 3, 4,5,6, 10, 11, 22, 23)])
str(usr)
summary(usr[, -c(1,2,11,12,15,16,17)])

summary(all.ds)
summary(myusrAni)

#nearZeroVar check
colnames(ani[, c(nearZeroVar(ani))])
colnames(usr[, c(nearZeroVar(usr))])
colnames(myusrAni[,c(nearZeroVar(myusrAni))])

```



